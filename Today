#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec
from matplotlib.patches import Rectangle
import numpy as np
import os
import warnings
import sys

warnings.filterwarnings('ignore')

# ============================================
# CONFIGURATION: Set your server name here
# ============================================
SERVER_NAME = "PROD-SERVER-01"
# ============================================

# Read CSV file
df = pd.read_csv('your_data.csv')

# Convert date to datetime
df['Date'] = pd.to_datetime(df['Date'].str.replace(r' CDT| CST| EST| PST| MST', '', regex=True))
df = df.sort_values('Date').reset_index(drop=True)

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = '#fafbfc'
plt.rcParams['grid.alpha'] = 0.3
plt.rcParams['font.family'] = 'sans-serif'

# Create figure - EXPANDED to include legend panel
fig = plt.figure(figsize=(28, 24))
gs = GridSpec(7, 5, figure=fig, hspace=0.4, wspace=0.35, top=0.95, bottom=0.02, left=0.04, right=0.98)

# Color palette
colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', 
          '#BC4749', '#F77F00', '#06AED5', '#9D4EDD', '#118AB2',
          '#073B4C', '#EF476F', '#FFD166', '#06FFA5', '#8338EC']

def create_scatter(ax, x, y, color, title, description=""):
    ax.scatter(x, y, alpha=0.6, color=color, s=40, edgecolors='white', linewidth=0.8)
    
    if len(x) > 2 and x.std() > 0 and not np.isnan(x).any() and not np.isnan(y).any():
        try:
            z = np.polyfit(x, y, 1)
            p = np.poly1d(z)
            ax.plot(x, p(x), "--", color=color, alpha=0.4, linewidth=2)
            
            corr = np.corrcoef(x, y)[0, 1]
            if abs(corr) >= 0.7:
                strength = "Strong"
                emoji = "Fire"
            elif abs(corr) >= 0.4:
                strength = "Moderate"
                emoji = "Arrow"
            else:
                strength = "Weak"
                emoji = "Wave"
            
            corr_text = f"{emoji} {corr:.2f}\n{strength}"
            ax.text(0.95, 0.05, corr_text, transform=ax.transAxes, 
                   fontsize=8, ha='right', va='bottom',
                   bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8))
        except:
            pass
    
    ax.set_title(title, fontsize=12, fontweight='bold', pad=8)
    ax.set_xlabel('Connections', fontsize=10)
    
    if description:
        ax.text(0.5, -0.25, description, transform=ax.transAxes, 
               fontsize=8, ha='center', va='top', style='italic', color='#666')
    
    ax.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.tick_params(labelsize=9)

# Summary Cards
ax_summary = fig.add_subplot(gs[0, :4])
ax_summary.axis('off')

avg_conn = df['Connections'].mean()
max_conn = df['Connections'].max()
avg_cpu = df['CPU (% used)'].mean()
total_discarded = df['Discarded events'].sum()

card_width = 0.19
cards_data = [
    {'title': 'Average\nConnections', 'value': f"{avg_conn:.0f}", 'color': '#2E86AB', 'desc': 'Typical load'},
    {'title': 'Peak\nConnections', 'value': f"{max_conn:.0f}", 'color': '#A23B72', 'desc': 'Maximum seen'},
    {'title': 'Average\nCPU Load', 'value': f"{avg_cpu:.1f}%", 'color': '#F18F01', 'desc': 'Processor usage'},
    {'title': 'Average\nMemory Used', 'value': f"{df['Memory (used GB)'].mean():.1f}GB", 'color': '#6A994E', 'desc': 'RAM consumed'},
    {'title': 'Total Events\nDiscarded', 'value': f"{total_discarded:.0f}", 'color': '#C73E1D', 'desc': 'Data lost'},
]

for i, card in enumerate(cards_data):
    x_pos = 0.02 + i * (card_width + 0.01)
    rect = Rectangle((x_pos, 0.15), card_width, 0.7, transform=ax_summary.transAxes,
                     facecolor=card['color'], alpha=0.15, edgecolor=card['color'], linewidth=2)
    ax_summary.add_patch(rect)
    ax_summary.text(x_pos + card_width/2, 0.7, card['title'], transform=ax_summary.transAxes,
                   fontsize=10, ha='center', fontweight='bold', color='#333')
    ax_summary.text(x_pos + card_width/2, 0.45, card['value'], transform=ax_summary.transAxes,
                   fontsize=16, ha='center', fontweight='bold', color=card['color'])
    ax_summary.text(x_pos + card_width/2, 0.25, card['desc'], transform=ax_summary.transAxes,
                   fontsize=8, ha='center', style='italic', color='#666')

# Connection Timeline
ax_timeline = fig.add_subplot(gs[0, 4])
ax_timeline.plot(df['Date'], df['Connections'], linewidth=2.5, color='#2E86AB', marker='o', markersize=3)
ax_timeline.fill_between(df['Date'], df['Connections'], alpha=0.2, color='#2E86AB')
ax_timeline.set_title('Connection Timeline', fontsize=12, fontweight='bold', pad=8)
ax_timeline.set_ylabel('Active Connections', fontsize=10)
ax_timeline.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
ax_timeline.tick_params(axis='x', rotation=45, labelsize=8)
ax_timeline.tick_params(axis='y', labelsize=9)
ax_timeline.spines['top'].set_visible(False)
ax_timeline.spines['right'].set_visible(False)
ax_timeline.text(0.5, -0.40, 'How many connections over time (line up = busier)', 
                transform=ax_timeline.transAxes, fontsize=8, ha='center', style='italic', color='#666')

# Row 1: Events & Volumes
ax1 = fig.add_subplot(gs[1, 0])
create_scatter(ax1, df['Connections'], df['Out-of-sync events'], colors[0], 'Out-of-sync Events',
              'When data fails to sync properly (lower is better)')
ax1.set_ylabel('Events', fontsize=10)

ax2 = fig.add_subplot(gs[1, 1])
create_scatter(ax2, df['Connections'], df['Discarded events'], colors[1], 'Discarded Events',
              'Data rejected/lost due to errors (0 is ideal)')
ax2.set_ylabel('Events', fontsize=10)

ax3 = fig.add_subplot(gs[1, 2])
create_scatter(ax3, df['Connections'], df['Input volume (MB)'], colors[2], 'Input Volume (MB)',
              'Total incoming data received by server')
ax3.set_ylabel('MB', fontsize=10)

ax4 = fig.add_subplot(gs[1, 3])
create_scatter(ax4, df['Connections'], df['Input volume rate (MB/s)'], colors[3], 'Input Rate (MB/s)',
              'How fast data comes in (higher = more throughput)')
ax4.set_ylabel('MB/s', fontsize=10)

# Correlation heatmap
ax_corr = fig.add_subplot(gs[1, 4])
key_metrics = ['Connections', 'CPU (% used)', 'Memory (used %)', 'Input volume (MB)']
corr_mini = df[key_metrics].corr()

annot_labels = []
for i in range(len(corr_mini)):
    row_labels = []
    for j in range(len(corr_mini)):
        val = corr_mini.iloc[i, j]
        if i == j:
            row_labels.append('---')
        elif abs(val) >= 0.7:
            row_labels.append(f'{val:.2f}\nStrong')
        elif abs(val) >= 0.4:
            row_labels.append(f'{val:.2f}\nModerate')
        else:
            row_labels.append(f'{val:.2f}\nWeak')
    annot_labels.append(row_labels)

sns.heatmap(corr_mini, annot=annot_labels, fmt='', cmap='RdYlBu_r', center=0, 
            square=True, linewidths=1, cbar=False, ax=ax_corr, annot_kws={'fontsize': 7})
ax_corr.set_title('Relationship Strength', fontsize=12, fontweight='bold', pad=8)
ax_corr.tick_params(labelsize=8)

explanation = ('Shows how metrics move together:\nRed = Move opposite ways\nBlue = Move same direction\nStrong/Moderate/Weak = How closely related')
ax_corr.text(0.5, -0.30, explanation, transform=ax_corr.transAxes, fontsize=8, ha='center', va='top', 
            style='italic', color='#333', bbox=dict(boxstyle='round,pad=0.4', facecolor='lightyellow', alpha=0.9))

# Row 2: GEMNI & SMANPD
ax5 = fig.add_subplot(gs[2, 0])
create_scatter(ax5, df['Connections'], df['GEMNI output volume (MB)'], colors[4], 'GEMNI Volume (MB)',
              'How much data GEMNI processes')
ax5.set_ylabel('MB', fontsize=10)

ax6 = fig.add_subplot(gs[2, 1])
create_scatter(ax6, df['Connections'], df['GEMNI output rate (MB/s)'], colors[5], 'GEMNI Rate (MB/s)',
              'GEMNI processing speed')
ax6.set_ylabel('MB/s', fontsize=10)

ax7 = fig.add_subplot(gs[2, 2])
create_scatter(ax7, df['Connections'], df['SMANPD output volume (MB)'], colors[6], 'SMANPD Volume (MB)',
              'How much data SMANPD processes')
ax7.set_ylabel('MB', fontsize=10)

ax8 = fig.add_subplot(gs[2, 3])
create_scatter(ax8, df['Connections'], df['SMANPD output rate (MB/s)'], colors[7], 'SMANPD Rate (MB/s)',
              'SMANPD processing speed')
ax8.set_ylabel('MB/s', fontsize=10)

# Output comparison
ax_output = fig.add_subplot(gs[2, 4])
ax_output.scatter(df['GEMNI output rate (MB/s)'], df['SMANPD output rate (MB/s)'], 
                 alpha=0.6, color=colors[8], s=50, edgecolors='white', linewidth=0.8)
ax_output.set_xlabel('GEMNI Speed (MB/s)', fontsize=10)
ax_output.set_ylabel('SMANPD Speed (MB/s)', fontsize=10)
ax_output.set_title('Processing Speed Comparison', fontsize=12, fontweight='bold', pad=8)
ax_output.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
ax_output.spines['top'].set_visible(False)
ax_output.spines['right'].set_visible(False)
ax_output.text(0.5, -0.30, 'Are both components processing at similar speeds?', 
              transform=ax_output.transAxes, fontsize=8, ha='center', style='italic', color='#666')

# Row 3: Memory & CPU
ax9 = fig.add_subplot(gs[3, 0])
create_scatter(ax9, df['Connections'], df['Memory (used GB)'], colors[10], 'Memory Used (GB)',
              'Actual RAM being used (like computer memory)')
ax9.set_ylabel('GB', fontsize=10)

ax10 = fig.add_subplot(gs[3, 1])
create_scatter(ax10, df['Connections'], df['Memory (used %)'], colors[11], 'Memory Usage (%)',
              'Percentage of available RAM in use')
ax10.set_ylabel('%', fontsize=10)
ax10.axhline(y=50, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='50% Warning')
ax10.axhline(y=80, color='red', linestyle='--', linewidth=1, alpha=0.5, label='80% Critical')
ax10.legend(fontsize=7, loc='upper left')

ax11 = fig.add_subplot(gs[3, 2])
if df['Connections'].max() > 0:
    memory_efficiency = (df['Memory (used GB)'] / (df['Connections'] / 1000))
    ax11.scatter(df['Connections'], memory_efficiency, alpha=0.6, color=colors[9], s=40, edgecolors='white', linewidth=0.8)
    ax11.set_title('Memory Efficiency', fontsize=12, fontweight='bold', pad=8)
    ax11.set_xlabel('Connections', fontsize=10)
    ax11.set_ylabel('GB per 1K Conn', fontsize=10)
    ax11.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
    ax11.spines['top'].set_visible(False)
    ax11.spines['right'].set_visible(False)
    ax11.tick_params(labelsize=9)
    ax11.text(0.5, -0.30, 'How much RAM each 1000 connections use (lower is better)', 
             transform=ax11.transAxes, fontsize=8, ha='center', style='italic', color='#666')

ax12 = fig.add_subplot(gs[3, 3])
create_scatter(ax12, df['Connections'], df['CPU (% used)'], colors[12], 'Total CPU Usage (%)',
              'How hard the processor is working (higher = busier)')
ax12.set_ylabel('%', fontsize=10)

# CPU vs Memory
ax_resource = fig.add_subplot(gs[3, 4])
scatter = ax_resource.scatter(df['CPU (% used)'], df['Memory (used %)'], 
                             c=df['Connections'], cmap='viridis', s=50, alpha=0.6, edgecolors='white', linewidth=0.8)
ax_resource.set_xlabel('CPU Usage (%)', fontsize=10)
ax_resource.set_ylabel('Memory Usage (%)', fontsize=10)
ax_resource.set_title('CPU vs Memory Usage', fontsize=12, fontweight='bold', pad=8)
ax_resource.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
ax_resource.spines['top'].set_visible(False)
ax_resource.spines['right'].set_visible(False)
cbar = plt.colorbar(scatter, ax=ax_resource)
cbar.set_label('Connections', fontsize=9)
cbar.ax.tick_params(labelsize=8)
ax_resource.text(0.5, -0.30, 'Do CPU and memory increase together? (color = connection count)', 
                transform=ax_resource.transAxes, fontsize=8, ha='center', style='italic', color='#666')

# Row 4: CPU Breakdown & Disk
ax13 = fig.add_subplot(gs[4, 0])
create_scatter(ax13, df['Connections'], df['CPU (user %)'], colors[13], 'CPU User (%)',
              'Processor used by applications/programs')
ax13.set_ylabel('%', fontsize=10)

ax14 = fig.add_subplot(gs[4, 1])
create_scatter(ax14, df['Connections'], df['CPU (system %)'], colors[14], 'CPU System (%)',
              'Processor used by operating system')
ax14.set_ylabel('%', fontsize=10)

ax15 = fig.add_subplot(gs[4, 2])
create_scatter(ax15, df['Connections'], df['Disk data0 (% used)'], colors[1], 'Disk Usage (%)',
              'How full the storage drive is (like hard disk)')
ax15.set_ylabel('%', fontsize=10)

# Connection Pattern
ax_pattern = fig.add_subplot(gs[4, 3])
ax_pattern.scatter(df.index, df['Connections'], alpha=0.6, color=colors[0], s=30)
ax_pattern.set_xlabel('Data Point Number', fontsize=10)
ax_pattern.set_ylabel('Connections', fontsize=10)
ax_pattern.set_title('Connection Pattern', fontsize=12, fontweight='bold', pad=8)
ax_pattern.grid(True, alpha=0.25, linestyle='--', linewidth=0.5)
ax_pattern.spines['top'].set_visible(False)
ax_pattern.spines['right'].set_visible(False)
ax_pattern.text(0.5, -0.30, 'Connection trend across all measurements', 
               transform=ax_pattern.transAxes, fontsize=8, ha='center', style='italic', color='#666')

# Insights Panel
ax_insights = fig.add_subplot(gs[4, 4])
ax_insights.axis('off')

conn_cpu_corr = df['Connections'].corr(df['CPU (% used)'])
conn_mem_corr = df['Connections'].corr(df['Memory (used %)'])
conn_disc_corr = df['Connections'].corr(df['Discarded events'])

insights_text = f"""
KEY INSIGHTS
{'='*30}

Data Points: {len(df)}
Time Range: {(df['Date'].max() - df['Date'].min()).days} days

CONNECTION IMPACT:
â€¢ CPU: {conn_cpu_corr:+.3f} correlation
â€¢ Memory: {conn_mem_corr:+.3f} correlation  
â€¢ Discarded: {conn_disc_corr:+.3f} correlation

RESOURCE PEAKS:
â€¢ Max CPU: {df['CPU (% used)'].max():.1f}%
â€¢ Max Memory: {df['Memory (used GB)'].max():.1f} GB ({df['Memory (used %)'].max():.1f}%)
â€¢ Max Disk: {df['Disk data0 (% used)'].max():.1f}%

THROUGHPUT:
â€¢ Avg Input: {df['Input volume rate (MB/s)'].mean():.1f} MB/s
â€¢ Avg GEMNI: {df['GEMNI output rate (MB/s)'].mean():.1f} MB/s
â€¢ Avg SMANPD: {df['SMANPD output rate (MB/s)'].mean():.1f} MB/s

LEGEND:
â€¢ Correlation: How closely related
â€¢ Dotted line: Trend direction
â€¢ Colors: Identify different metrics
"""

ax_insights.text(0.05, 0.95, insights_text, transform=ax_insights.transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round,pad=0.8', facecolor='#f0f4f8', 
                         edgecolor='#2E86AB', linewidth=2, alpha=0.9))

# Titles
fig.suptitle(f'{SERVER_NAME} - PERFORMANCE DASHBOARD', fontsize=28, fontweight='bold', y=0.98, x=0.5, ha='center')
subtitle = f"Executive Summary | {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')} | Scroll down for detailed metric explanations"
fig.text(0.5, 0.965, subtitle, fontsize=11, ha='center', color='#666', style='italic')

# Guide at bottom - COMPREHENSIVE LEGEND FOR NON-TECHNICAL READERS
legend_box = fig.add_subplot(gs[5:, :])
legend_box.axis('off')

legend_content = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“š CHART GUIDE - What Each Metric Means (Plain Language)

CONNECTION METRICS:
  â€¢ Connections: Number of active users/sessions connected to the server at once. Higher = more traffic/load
  â€¢ Connection Timeline: Shows how busy the server is over time. Peaks indicate high demand periods

DATA FLOW METRICS:
  â€¢ Input Volume (MB): Total amount of data the server receives. Like packages arriving at a warehouse
  â€¢ Input Rate (MB/s): Speed of incoming data per second. Higher = faster data flow
  â€¢ GEMNI Volume/Rate: Data processed by the GEMNI component (part of the system that handles specific tasks)
  â€¢ SMANPD Volume/Rate: Data processed by the SMANPD component (another system component with different role)

ERROR & QUALITY METRICS:
  â€¢ Out-of-sync Events: Times when data failed to synchronize properly. Should be close to ZERO (0 = perfect)
  â€¢ Discarded Events: Data packets rejected/lost due to errors or overload. Lower is better (0 = ideal)

SYSTEM RESOURCES:
  â€¢ CPU Usage (%): How hard the processor is working. Like engine RPM in a car. 80%+ means very busy
  â€¢ CPU User (%): Processor power used by applications
  â€¢ CPU System (%): Processor power used by the operating system itself
  â€¢ Memory Used (GB): Amount of RAM being consumed. Like active workspace in use
  â€¢ Memory Usage (%): Percentage of total available RAM in use. 50% = half full, 80%+ = getting full
  â€¢ Memory Efficiency: RAM used per 1000 connections. Lower = more efficient
  â€¢ Disk Usage (%): How full the storage drive is. Like hard drive space. 80%+ means nearly full

UNDERSTANDING THE CHARTS:
  ðŸ“ˆ Scatter Plots: Each dot is one measurement. If dots go up-right, metric increases with more connections
  ðŸ“Š Trend Lines (dotted): Shows general direction. Upward = increases, flat = no change, downward = decreases
  ðŸŽ¯ Correlation Values: Shows relationship strength
      â€¢ "Strong" (0.7-1.0): Very closely related - one affects the other significantly
      â€¢ "Moderate" (0.4-0.7): Somewhat related - some influence on each other
      â€¢ "Weak" (0.0-0.4): Little relationship - mostly independent
  ðŸŽ¨ Heatmap Colors: 
      â€¢ BLUE = Metrics move together (both increase or both decrease)
      â€¢ RED = Metrics move opposite (one up, other down)
      â€¢ WHITE = No clear relationship

KEY BUSINESS QUESTIONS THIS DASHBOARD ANSWERS:
  âœ“ Can our server handle more connections? (Look at CPU & Memory vs Connections)
  âœ“ Are we losing data under load? (Check Discarded Events)
  âœ“ Is performance degrading with traffic? (Check if rates stay steady or drop)
  âœ“ What's our bottleneck? (Find the metric with strongest correlation to connections)
  âœ“ Do we need more resources? (If CPU/Memory > 80% consistently = YES)

WHAT TO WATCH FOR (RED FLAGS):
  ðŸš¨ Discarded Events > 0: We're losing data - investigate immediately
  ðŸš¨ CPU > 80%: Processor maxed out - performance will suffer
  ðŸš¨ Memory > 80%: RAM nearly full - risk of crashes
  ðŸš¨ Strong correlation + high values: This metric is our limiting factor

WHAT GOOD LOOKS LIKE:
  âœ… Discarded Events = 0: No data loss
  âœ… CPU < 70%: Healthy headroom for growth
  âœ… Memory < 70%: Adequate resources
  âœ… Rates increase linearly: System scales well
  âœ… Weak correlation on errors: Stable under any load

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

legend_box.text(0.5, 0.5, legend_content, transform=legend_box.transAxes,
                fontsize=9, ha='center', va='center', fontfamily='monospace',
                bbox=dict(boxstyle='round,pad=1.2', facecolor='#f9f9f9', 
                         edgecolor='#2E86AB', linewidth=3, alpha=0.98))

# Save and exit
output_file = os.path.join(os.getcwd(), f'{SERVER_NAME}.png')
plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
plt.close('all')
print(f"\nDashboard saved: {output_file}")

# Print correlation analysis
print(f"\n{'='*60}")
print(f"  {SERVER_NAME} - PERFORMANCE ANALYSIS COMPLETE")
print(f"{'='*60}")
print(f"\nCorrelation Analysis (vs Connections):")
metrics_to_analyze = ['Out-of-sync events', 'Discarded events', 'Input volume (MB)', 
                      'CPU (% used)', 'Memory (used %)', 'Disk data0 (% used)']
for metric in metrics_to_analyze:
    corr = df['Connections'].corr(df[metric])
    strength = 'Strong' if abs(corr) > 0.7 else 'Moderate' if abs(corr) > 0.4 else 'Weak'
    print(f"  â€¢ {metric:.<40} {corr:+.3f} ({strength})")

print(f"\n{'='*60}\n")
print("Script completed successfully. Exiting...")
sys.exit(0)
